
# Information about all exercises in the file main_analysis.do.txt.
# The information can be loaded into a Python list of dicts by
#
# f = open('.main_analysis.exerinfo', 'r')
# exer = eval(f.read())
#
[{'answer': '',
  'chapter_exercise': None,
  'chapter_no': None,
  'chapter_title': None,
  'chapter_type': None,
  'closing_remarks': '',
  'file': ['decay_plot_fd_error'],
  'heading': '=====',
  'hints': ['To save manual calculations and learn more about symbolic computing,\nmake functions for the three difference operators and use `sympy`\nto perform the symbolic differences, differentiation, and Taylor series\nexpansion. To plot a symbolic expression `E` against `p`, convert the\nexpression to a Python function first: `E = sympy.lamdify([p], E)`.'],
  'keywords': None,
  'label': 'decay:analysis:exer:fd:exp:plot',
  'no': 1,
  'solution': "Here is Python code for the exercise:\n\n!bc pypro\nimport sympy as sym\n\n# Define finite difference operators as functions\n\ndef D_f(u, dt, t):\n    return (u(t + dt) - u(t))/dt\n\ndef D_b(u, dt, t):\n    return (u(t) - u(t - dt))/dt\n\ndef D_c(u, dt, t):\n    return (u(t + dt) - u(t - dt))/(2*dt)\n\n\ndef make_plot():\n    def u(t):\n        return sym.exp(-a*t)\n\n    a, t, dt, p = sym.symbols('a t dt p')\n    dudt = sym.diff(u(t), t)\n\n    from numpy import logspace, exp\n    from matplotlib.pyplot import (\n        semilogx, legend, show, loglog, savefig)\n\n    # Map operator function name to logical names\n    operator2name = dict(\n        D_f='forward', D_b='backward', D_c='central')\n    legends = []\n    for operator in D_f, D_b, D_c:\n        E = operator(u, dt, t)/dudt\n        # Expand, set p=a*dt, simplify\n        E = sym.expand(E)\n        E = E.subs(a*dt, p)\n        E = sym.simplify(E)\n        print '%s E:' % operator2name[operator.__name__], E\n        print 'Taylor series:', E.series(p, 0, 3)\n        latex_expr = sym.latex(E)\n\n        E = sym.lambdify([p], E, modules='numpy')\n        p_values = logspace(-6, -0.5, 101)\n        y = E(p_values)\n        semilogx(p_values, y)\n        legends.append(operator2name[operator.__name__] +\n                       ': $' + latex_expr + '$')\n    legend(legends, loc='lower left')\n    savefig('tmp.png'); savefig('tmp.pdf')\n    show()\n\nmake_plot()\n\n!ec\nThe output of the Taylor polynomials reads\n\n!bc\nforward E: (exp(p) - 1)*exp(-p)/p\nTaylor series: 1 - p/2 + p**2/6 + O(p**3)\nbackward E: (exp(p) - 1)/p\nTaylor series: 1 + p/2 + p**2/6 + O(p**3)\ncentral E: sinh(p)/p\nTaylor series: 1 + p**2/6 + O(p**3)\n\n!ec \n\nFIGURE: [fig-analysis/decay_plot_fd_error, width=700 frac=0.9] Plot for Exercise ref{decay:analysis:exer:fd:exp:plot}.",
  'solution_file': None,
  'subex': [],
  'text': "The purpose of this exercise is to visualize the accuracy of finite difference\napproximations of the derivative of a given function.\nFor any finite difference approximation, take the Forward Euler difference\nas an example, and any specific function, take  $u=e^{-at}$,\nwe may introduce an error fraction\n\n!bt\n\\begin{align*}\nE = \\frac{[D_t^+ u]^n}{u'(t_n)} &= \\frac{\\exp{(-a(t_n+\\Delta t))} - \\exp{(-at_n)}}{-a\\exp{(-at_n)\\Delta t}}\\\\ \n&= \\frac{1}{a\\Delta t}\\left(1 -\\exp{(-a\\Delta t)}\\right),\n\\end{align*}\n\n!et\nand view $E$ as a function of $\\Delta t$. We expect that\n$\\lim_{\\Delta t\\rightarrow 0}E=1$, while $E$ may deviate significantly from\nunity for large $\\Delta t$. How the error depends on $\\Delta t$ is best\nvisualized in a graph where we use a logarithmic scale for $\\Delta t$,\nso we can cover many orders of magnitude of that quantity. Here is\na code segment creating an array of 100 intervals, on the logarithmic\nscale, ranging from $10^{-6}$ to $10^{-0.5}$ and then plotting $E$ versus\n$p=a\\Delta t$ with logarithmic scale on the $p$ axis:\n\n!bc pycod\nfrom numpy import logspace, exp\nfrom matplotlib.pyplot import semilogx\np = logspace(-6, -0.5, 101)\ny = (1-exp(-p))/p\nsemilogx(p, y)\n\n!ec\nIllustrate such errors for the finite difference operators $[D_t^+u]^n$\n(forward), $[D_t^-u]^n$ (backward), and $[D_t u]^n$ (centered) in\nthe same plot.\n\nPerform a Taylor series expansions of the error fractions and find\nthe leading order $r$ in the expressions of type\n$1 + Cp^r + \\Oof{p^{r+1}}$, where $C$ is some constant.",
  'title': 'Visualize the accuracy of finite differences',
  'type': 'Problem',
  'type_visible': True},
 {'answer': '',
  'chapter_exercise': None,
  'chapter_no': None,
  'chapter_title': None,
  'chapter_type': None,
  'closing_remarks': '',
  'file': ['exponential_growth'],
  'heading': '=====',
  'hints': [],
  'keywords': None,
  'label': 'decay:analysis:exer:growth',
  'no': 2,
  'solution': '',
  'solution_file': None,
  'subex': [{'answer': '',
             'file': None,
             'hints': [],
             'solution': '#Does not work: @@@CODE exer-analysis/exponential_growth.do.txt envir=None fromto: The schemes are@=== Analysis\n\nThe schemes are exactly the same as in the case $a>0$.\nA program solving the problem numerically is shown below.\n\n!bc pycod\nfrom numpy import *\n\n# Exercise a\n\ndef solver(I, a, T, dt, theta):\n    """Solve u\'=-a*u, u(0)=I, for t in (0,T] with steps of dt."""\n    dt = float(dt)            # avoid integer division\n    Nt = int(round(T/dt))     # no of time intervals\n    T = Nt*dt                 # adjust T to fit time step dt\n    u = zeros(Nt+1)           # array of u[n] values\n    t = linspace(0, T, Nt+1)  # time mesh\n\n    u[0] = I                  # assign initial condition\n    for n in range(0, Nt):    # n=0,1,...,Nt-1\n        u[n+1] = (1 - (1-theta)*a*dt)/(1 + theta*dt*a)*u[n]\n    return u, t\n\ndef u_exact(t, I, a):\n    return I*exp(-a*t)\n\ndef numerical_and_exact(theta, I, a, T, dt):\n    """Compare the numerical and exact solution in a plot."""\n    u, t = solver(I=I, a=a, T=T, dt=dt, theta=theta)\n\n    t_e = linspace(0, T, 1001)        # fine mesh for u_e\n    u_e = u_exact(t_e, I, a)\n    return u, t, u_e, t_e\n\ndef demo(dt):\n    from matplotlib.pyplot import (\n        plot, xlabel, ylabel, legend, title, savefig, show)\n    for theta in [0, 0.5, 1]:\n        u, t, u_e, t_e = numerical_and_exact(\n            I=1, a=-1, T=2.5, dt=dt, theta=theta)\n        xlabel(\'t\')\n        ylabel(\'u\')\n        plot(t,   u)\n\n    plot(t_e, u_e, \'k-\')  # black line\n    legend([\'FE\', \'CN\', \'BE\', \'exact\'], loc=\'upper left\')\n    title(\'Timestep: %g\' % dt)\n    savefig(\'tmp_%g.png\' % dt); savefig(\'tmp_%g.pdf\' % dt)\n    show()\n\n!ec\n\nWe can try different $\\Delta t$ values: 3, 0.5, 0.1, and 0.01.\n\nFIGURE: [fig-analysis/exponential_growth_demo, width=800 frac=1]',
             'text': 'Set $a=-1$ and run experiments with $\\theta=0, 0.5, 1$ for\nvarious values of $\\Delta t$ to uncover numerical artifacts.\nRecall that the exact solution is a\nmonotone, growing function when $a < 0$. Oscillations or significantly\nwrong growth are signs of wrong qualitative behavior.\n\nFrom the experiments, select four values of $\\Delta t$ that\ndemonstrate the kind of numerical solutions that are characteristic\nfor this model.'},
            {'answer': '',
             'file': None,
             'hints': ['Modify the "`decay_ampf_plot.py`": "http://tinyurl.com/ofkw6kc/analysis/decay_ampf_plot.py" code\n(in the `src/analysis` directory).'],
             'solution': "#@@@CODE exer-analysis/exponential_growth.do.txt envir=None fromto: === Analysis@\n\nThe amplification factor is the same as when $a>0$, but here we introduce\n$p=-a\\Delta t>0$ since $a < 0$:\n\n!bt\n\\begin{equation}\nA(p) = \\frac{1+(1-\\theta)p}{1-\\theta p}.\nlabel{_auto7}\n\\end{equation}\n\n!et\nA major problem is that the denominator can be zero when $a < 0$. This\nhappens for $p=1/\\theta$. The exact amplification factor is $\\Aex = e^{p}$.\n\nHere is code for computing and plotting the factors:\n\n!bc pycod\n# Exercise b\n\ndef plot_amplification_factors(names):\n    # Substitute -p by p since a is negative for a growth model\n\n    def A_exact(p):\n        return exp(p)\n\n    def A(p, theta):\n        return (1+(1-theta)*p)/(1-theta*p)\n\n    def amplification_factor(names):\n        # Use SciTools since it adds markers to colored lines\n        from scitools.std import (\n            plot, title, xlabel, ylabel, hold, savefig,\n            axis, legend, grid, show, figure)\n        figure()\n        curves = {}\n        p = linspace(0, 3, 99)\n        curves['exact'] = A_exact(p)\n        plot(p, curves['exact'])\n        hold('on')\n        name2theta = dict(FE=0, BE=1, CN=0.5)\n        for name in names:\n            curves[name] = A(p, name2theta[name])\n            plot(p, curves[name])\n            axis([p[0], p[-1], -20, 20])\n            #semilogy(p, curves[name])\n        plot([p[0], p[-1]], [0, 0], '--')  # A=0 line\n        title('Amplification factors')\n        grid('on')\n        legend(['exact'] + names, loc='lower left', fancybox=True)\n        xlabel(r'$p=-a\\cdot dt$')\n        ylabel('Amplification factor')\n        savefig('A_growth.png'); savefig('A_growth.pdf')\n        #show()\n\n    amplification_factor(names)\n\n!ec\n\nFIGURE: [fig-analysis/A_growth, width=700 frac=0.9]",
             'text': 'Write up the amplification factor and plot it for $\\theta=0,0.5,1$\ntogether with the exact one for $a\\Delta t < 0$. Use the plot to\nexplain the observations made in the experiments.'}],
  'text': "This exercise asks you to solve the ODE $u'=-au$ with $a < 0$ such that\nthe ODE models exponential growth instead of exponential decay.  A\ncentral theme is to investigate numerical artifacts and non-physical\nsolution behavior.",
  'title': 'Explore the $\\theta$-rule for exponential growth',
  'type': 'Problem',
  'type_visible': True}]